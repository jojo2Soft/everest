# -*- coding: utf-8 -*-
"""classificationAndRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZmrX9Ar-BqOA94W-i9OApZ52xzo8tZQ2
"""

# prompt: stp genere moi le code qui permet de faire le deepleaning avec sur un probleme de classification avec une base de donneees populaire

# Importer les librairies nécessaires
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

# Charger la base de données MNIST
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Prétraiter les données
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
y_train = keras.utils.to_categorical(y_train, num_classes=10)
y_test = keras.utils.to_categorical(y_test, num_classes=10)

# Définir le modèle
model = keras.Sequential(
    [
        keras.Input(shape=(28, 28)),
        layers.Flatten(),
        layers.Dense(128, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)

# Compiler le modèle
model.compile(
    loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"]
)

# Entraîner le modèle
model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.1)

# Évaluer le modèle
score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

#passsons a notre projet

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras import models, layers, optimizers
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

#chargemenet des donnees
#x_train est la bd d'entraiment de notre model
#y_train c'est la valeurs aqui  va nous dire si est possibif ou negatif
#x_test  enmsebre des catrest de notre bd test
#y_test c'est la valeurs aqui  va nous dire si est possibif ou negatif

max_len = 500
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)

x_train #donner texter on doit toit tout transformemr en des chiffre car les aglo d'optimasion se base sur les donnees numerique

y_train

#visionnner a quoi correspondont nos chiffres
(train_data, train_labels), (test_data, test_labels) = imdb.load_data()

word_index = imdb.get_word_index()

#reverse
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

#fonction pour convertir une critique d'un fiml en forme de mot
def decode_review(text):
    return " ".join([reverse_word_index.get(i, "?") for i in text])

#affichage d'une critique
decode_review = decode_review(train_data[0])
print(decode_review)

#affichons le label correspondant
print(train_labels[0])

#comment tranformation du texte en chiffre pour faire du ML
#ralisation du padding
x_train = pad_sequences(x_train, maxlen=max_len)
x_test = pad_sequences(x_test, maxlen=max_len)

model = models.Sequential()
model.add(layers.Embedding(10000, 128, input_length=max_len))
model.add(layers.Dropout(0.5))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.summary()

#definir la methodolgy pour antrainner
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

#evaluluation du model
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

#nous sommes en presence d'un  models qui surapprend
#Que faires ??
#la couche droupout permet de reugulaser certainne ponderation dans les reseaux de noeurnone onront un point qui est egale a 0

#evaluons le model
score = model.evaluate(x_test, y_test)
print(f'Test loss {score[0]}')
print(f'Test accuracy {score[1]}')

y_pred = ( model.predict(x_test) > 0.5).astype("int32")

#evaleons avec la matrice de confusion
conf_matrix = confusion_matrix(y_test, y_pred)

class_report = classification_report(y_test, y_pred)
print("Rapport")
print(conf_matrix)
print(class_report)

#affichons la matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show

"""**Model de regression : Nous allons predire le prix immobilier**"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import boston_housing
from tensorflow.keras import models, layers
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import RMSprop
from sklearn.preprocessing import StandardScaler

(x_train, y_train), (x_test, y_test) = boston_housing.load_data()

x_train

scaller = StandardScaler()
x_train = scaller.fit_transform(x_train)
x_test = scaller.transform(x_test)

#Un MLP
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(1))
model.summary()

model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])

history= model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.show()
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qp8fvTZvtx3h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#generation des dattaas\n",
        "np.random.seed(42)\n",
        "\n",
        "taill = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "age = np.random.randint(18, 90, size=taill)\n",
        "\n",
        "incom = np.random.randint(2000, 100000, size= taill)\n",
        "laound_amout = np.random.randint(5000, 100000, size=taill)\n",
        "num_accouunt = np.random.randint(1, 10, size=taill)\n",
        "\n",
        "#creation des caracteristique input\n",
        "\n",
        "x= np.column_stack((age, incom, laound_amout, num_accouunt)).T\n",
        "x\n",
        "\n",
        "#mecanisme de forword propagation\n",
        "\n",
        "#fonction relu\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "#fonction sigmoid\n",
        "def sigmoid(x):\n",
        "  return 1/(1/1+np.exp(-x))\n",
        "\n"
      ],
      "metadata": {
        "id": "eNXt2YwVvkRz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "#nomvre de renone\n",
        "hidden_size =5\n",
        "\n",
        "#la taille de mes x\n",
        "input_size = x.shape[0]\n",
        "\n",
        "w1 = np.random.rand(hidden_size, input_size)\n",
        "w1\n",
        "#on fixe les poid alleatoire c'est nombre b1\n",
        "b1= np.random.rand(hidden_size, 1)\n",
        "b1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krAJ0uyI0NtT",
        "outputId": "beb160c7-498b-42c3-e02b-d55e3d4549a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.61185289],\n",
              "       [0.13949386],\n",
              "       [0.29214465],\n",
              "       [0.36636184],\n",
              "       [0.45606998]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGd1W77Wslnu",
        "outputId": "c3b5292c-9438-4229-9ed7-0aa19735a75a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37454012, 0.95071431, 0.73199394, 0.59865848],\n",
              "       [0.15601864, 0.15599452, 0.05808361, 0.86617615],\n",
              "       [0.60111501, 0.70807258, 0.02058449, 0.96990985],\n",
              "       [0.83244264, 0.21233911, 0.18182497, 0.18340451],\n",
              "       [0.30424224, 0.52475643, 0.43194502, 0.29122914]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_size = 1\n",
        "w2 = np.random.rand(hidden_size, output_size)\n",
        "b2 = np.random.rand(hidden_size, 1)\n",
        "\n",
        "#on vient de definir plus haut les poid et les bia\n",
        "\n",
        "#forwoard pass notre combinaison lineaore\n",
        "z1 = np.dot(w1,x)+b1\n",
        "z1\n",
        "\n",
        "#apres la couche cahe nos x se transforme en a1\n",
        "a1 = relu(z1)\n",
        "\n",
        "w2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpoSaq3DsuoF",
        "outputId": "16c7067a-49af-46df-e6ca-e28457784f0b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32518332],\n",
              "       [0.72960618],\n",
              "       [0.63755747],\n",
              "       [0.88721274],\n",
              "       [0.47221493]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Génération des données\n",
        "np.random.seed(42)\n",
        "\n",
        "taille = 10\n",
        "age = np.random.randint(18, 90, size=taille)\n",
        "income = np.random.randint(2000, 100000, size=taille)\n",
        "loan_amount = np.random.randint(5000, 100000, size=taille)\n",
        "num_accounts = np.random.randint(1, 10, size=taille)\n",
        "\n",
        "# Création des caractéristiques d'entrée\n",
        "x = np.column_stack((age, income, loan_amount, num_accounts)).T\n",
        "print(\"Input Data (x):\\n\", x)\n",
        "\n",
        "# Mécanisme de forward propagation\n",
        "\n",
        "# Fonction ReLU\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Fonction sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "np.random.seed(42)\n",
        "# Nombre de neurones dans la couche cachée\n",
        "hidden_size = 5\n",
        "\n",
        "# Taille des entrées\n",
        "input_size = x.shape[0]\n",
        "\n",
        "# Poids et biais pour la première couche cachée\n",
        "w1 = np.random.rand(hidden_size, input_size)\n",
        "b1 = np.random.rand(hidden_size, 1)\n",
        "\n",
        "# Poids et biais pour la couche de sortie\n",
        "output_size = 1\n",
        "w2 = np.random.rand(output_size, hidden_size)\n",
        "b2 = np.random.rand(output_size, 1)\n",
        "\n",
        "# Forward pass : combinaison linéaire\n",
        "z1 = np.dot(w1, x) + b1\n",
        "print(\"\\nAfter first layer (z1):\\n\", z1)\n",
        "\n",
        "# Appliquer la fonction d'activation ReLU\n",
        "a1 = relu(z1)\n",
        "print(\"\\nAfter ReLU activation (a1):\\n\", a1)\n",
        "\n",
        "# Forward pass pour la couche de sortie\n",
        "z2 = np.dot(w2, a1) + b2\n",
        "print(\"\\nAfter second layer (z2):\\n\", z2)\n",
        "\n",
        "# Appliquer la fonction d'activation sigmoid\n",
        "output = sigmoid(z2)\n",
        "print(\"\\nFinal output after sigmoid activation:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CihKdcpDvNjR",
        "outputId": "772d59ab-c80c-4928-e03f-792da74994a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data (x):\n",
            " [[   69    32    89    78    38    41    20    39    70    19]\n",
            " [61735 64955 66925 69969  7311 85104 55707 87305 30693 73932]\n",
            " [98016 30658 89478 23431  7747 64150 70725 89654 40773 72435]\n",
            " [    7     4     9     3     5     3     7     5     9     7]]\n",
            "\n",
            "After first layer (z1):\n",
            " [[130470.11163729  84210.10981154 129163.24273171  83703.5013134\n",
            "   12639.26703121 127884.76567313 104744.00666645 148646.50959023\n",
            "   59058.08078369 123322.11000115]\n",
            " [ 15340.41305631  11921.94824523  15658.95946126  12290.64518637\n",
            "    1600.84876457  17010.95616584  12807.27331465  18837.08486485\n",
            "    7175.03931562  15749.44040595]\n",
            " [ 45779.02883256  46647.3411813   49292.13721896  50075.53432678\n",
            "    5364.17075793  61608.15155952  40919.5412642   63692.34383545\n",
            "   22623.26260036  53858.76236477]\n",
            " [ 30989.59971912  19394.61492313  30556.23379536  19183.34314303\n",
            "    2993.92546387  29770.02604515  24706.64469051  34873.35031514\n",
            "   13991.16169927  28886.6132339 ]\n",
            " [ 74756.84864277  47339.48113652  73799.05525692  46862.64714904\n",
            "    7196.245752    72381.94799289  59790.49749923  84553.23662815\n",
            "   33742.41749044  70092.50520536]]\n",
            "\n",
            "After ReLU activation (a1):\n",
            " [[130470.11163729  84210.10981154 129163.24273171  83703.5013134\n",
            "   12639.26703121 127884.76567313 104744.00666645 148646.50959023\n",
            "   59058.08078369 123322.11000115]\n",
            " [ 15340.41305631  11921.94824523  15658.95946126  12290.64518637\n",
            "    1600.84876457  17010.95616584  12807.27331465  18837.08486485\n",
            "    7175.03931562  15749.44040595]\n",
            " [ 45779.02883256  46647.3411813   49292.13721896  50075.53432678\n",
            "    5364.17075793  61608.15155952  40919.5412642   63692.34383545\n",
            "   22623.26260036  53858.76236477]\n",
            " [ 30989.59971912  19394.61492313  30556.23379536  19183.34314303\n",
            "    2993.92546387  29770.02604515  24706.64469051  34873.35031514\n",
            "   13991.16169927  28886.6132339 ]\n",
            " [ 74756.84864277  47339.48113652  73799.05525692  46862.64714904\n",
            "    7196.245752    72381.94799289  59790.49749923  84553.23662815\n",
            "   33742.41749044  70092.50520536]]\n",
            "\n",
            "After second layer (z2):\n",
            " [[150878.01119028 106177.12214249 151420.83363962 107468.54980152\n",
            "   15110.65870022 156488.69505674 123256.46725128 177815.35579325\n",
            "   69293.83812243 148039.62089727]]\n",
            "\n",
            "Final output after sigmoid activation:\n",
            " [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Génération des données\n",
        "np.random.seed(42)\n",
        "\n",
        "taille = 10\n",
        "age = np.random.randint(18, 90, size=taille)\n",
        "income = np.random.randint(2000, 100000, size=taille)\n",
        "loan_amount = np.random.randint(5000, 100000, size=taille)\n",
        "num_accounts = np.random.randint(1, 10, size=taille)\n",
        "\n",
        "# Création des caractéristiques d'entrée\n",
        "x = np.column_stack((age, income, loan_amount, num_accounts)).T\n",
        "\n",
        "# Normalisation des données\n",
        "x = (x - np.mean(x, axis=1, keepdims=True)) / np.std(x, axis=1, keepdims=True)\n",
        "\n",
        "# Mécanisme de forward propagation\n",
        "\n",
        "# Fonction ReLU\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Fonction sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "np.random.seed(42)\n",
        "# Nombre de neurones dans la couche cachée\n",
        "hidden_size = 5\n",
        "\n",
        "# Taille des entrées\n",
        "input_size = x.shape[0]\n",
        "\n",
        "# Poids et biais pour la première couche cachée\n",
        "w1 = np.random.randn(hidden_size, input_size) * 0.01\n",
        "b1 = np.zeros((hidden_size, 1))\n",
        "\n",
        "# Poids et biais pour la couche de sortie\n",
        "output_size = 1\n",
        "w2 = np.random.randn(output_size, hidden_size) * 0.01\n",
        "b2 = np.zeros((output_size, 1))\n",
        "\n",
        "# Forward pass : combinaison linéaire\n",
        "z1 = np.dot(w1, x) + b1\n",
        "print(\"\\nAfter first layer (z1):\\n\", z1)\n",
        "\n",
        "# Appliquer la fonction d'activation ReLU\n",
        "a1 = relu(z1)\n",
        "print(\"\\nAfter ReLU activation (a1):\\n\", a1)\n",
        "\n",
        "# Forward pass pour la couche de sortie\n",
        "z2 = np.dot(w2, a1) + b2\n",
        "print(\"\\nValues of z2 before sigmoid:\\n\", z2)\n",
        "\n",
        "# Appliquer la fonction d'activation sigmoid\n",
        "output = sigmoid(z2)\n",
        "print(\"\\nFinal output after sigmoid activation:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPcA6m8pyuvi",
        "outputId": "36ad6e73-cd66-4524-d8f9-f66c16452e3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After first layer (z1):\n",
            " [[ 0.02052105 -0.02374211  0.03691928 -0.02314933 -0.01687683 -0.02291055\n",
            "   0.00461815 -0.0035058   0.02442853  0.00369762]\n",
            " [ 0.02288704 -0.02057579  0.02307245 -0.03311236 -0.02396151 -0.00925103\n",
            "   0.01378548  0.01157517  0.00262061  0.01295996]\n",
            " [-0.01212204  0.01311307 -0.01793881  0.00848305 -0.0001515   0.01298696\n",
            "   0.00046857  0.00550932 -0.01500436  0.00465574]\n",
            " [-0.02496031  0.01581505 -0.02752058  0.02325632  0.07460063 -0.01672177\n",
            "  -0.00910509 -0.03890821  0.02875758 -0.0252136 ]\n",
            " [-0.02755461  0.02938255 -0.0461278   0.01924517  0.0193789   0.02464533\n",
            "   0.000984    0.00464577 -0.02795223  0.00335293]]\n",
            "\n",
            "After ReLU activation (a1):\n",
            " [[0.02052105 0.         0.03691928 0.         0.         0.\n",
            "  0.00461815 0.         0.02442853 0.00369762]\n",
            " [0.02288704 0.         0.02307245 0.         0.         0.\n",
            "  0.01378548 0.01157517 0.00262061 0.01295996]\n",
            " [0.         0.01311307 0.         0.00848305 0.         0.01298696\n",
            "  0.00046857 0.00550932 0.         0.00465574]\n",
            " [0.         0.01581505 0.         0.02325632 0.07460063 0.\n",
            "  0.         0.         0.02875758 0.        ]\n",
            " [0.         0.02938255 0.         0.01924517 0.0193789  0.02464533\n",
            "  0.000984   0.00464577 0.         0.00335293]]\n",
            "\n",
            "Values of z2 before sigmoid:\n",
            " [[ 2.49093067e-04 -3.76423223e-04  4.89014854e-04 -4.30382885e-04\n",
            "  -1.16836650e-03 -1.25395062e-04  3.15211913e-05 -4.77044083e-05\n",
            "  -5.76033004e-05  9.82476916e-06]]\n",
            "\n",
            "Final output after sigmoid activation:\n",
            " [[0.50006227 0.49990589 0.50012225 0.4998924  0.49970791 0.49996865\n",
            "  0.50000788 0.49998807 0.4999856  0.50000246]]\n"
          ]
        }
      ]
    }
  ]
}